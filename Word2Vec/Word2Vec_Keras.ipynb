{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.6-tf\n",
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# import keras\n",
    "import numpy as np\n",
    "import util\n",
    "print (keras.__version__)\n",
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified text8.zip\n",
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse']\n",
      "\n",
      "data: \n",
      "\t[0, 3081, 12, 6, 195]\n",
      "\n",
      "count: \n",
      "\t[['UNK', 2735459], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5000\n",
    "data, count, dictionary, reverse_dictionray = util.collect_data(vocabulary_size=vocab_size)\n",
    "print('\\ndata: \\n\\t{}'.format(data[:5]))\n",
    "print('\\ncount: \\n\\t{}'.format(count[:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK 0\n",
      "the 1\n",
      "of 2\n",
      "and 3\n",
      "one 4\n",
      "in 5\n",
      "a 6\n",
      "to 7\n",
      "zero 8\n",
      "nine 9\n",
      "two 10\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for x, y in dictionary.items():\n",
    "    print (x, y)\n",
    "    i += 1\n",
    "    if i > 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 UNK\n",
      "1 the\n",
      "2 of\n",
      "3 and\n",
      "4 one\n",
      "5 in\n",
      "6 a\n",
      "7 to\n",
      "8 zero\n",
      "9 nine\n",
      "10 two\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for x, y in reverse_dictionray.items():\n",
    "    print (x, y)\n",
    "    i += 1\n",
    "    if i > 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 3\n",
    "vector_dim = 300\n",
    "epochs = 200000\n",
    "\n",
    "valid_size = 16\n",
    "valid_window = 100\n",
    "valid_examples = np.random.choice(\n",
    "    valid_window,\n",
    "    valid_size,\n",
    "    replace=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample table created\n",
      "skipgrams created\n",
      "word_target and word_context zipped\n",
      "[[235, 2347], [400, 972], [871, 2987], [3100, 1085], [1491, 5], [1763, 3995], [3083, 21], [4382, 3546], [1850, 130], [1013, 2837]] [0, 0, 0, 1, 1, 0, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "sampling_table = keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "print ('sample table created')\n",
    "couples, labels = keras.preprocessing.sequence.skipgrams(\n",
    "    data,\n",
    "    vocab_size,\n",
    "    window_size = window_size,\n",
    "    sampling_table = sampling_table\n",
    ")\n",
    "print ('skipgrams created')\n",
    "word_target, word_context = zip(*couples)\n",
    "print ('word_target and word_context zipped')\n",
    "word_target = np.array(word_target, dtype='int32')\n",
    "word_context = np.array(word_context, dtype='int32')\n",
    "\n",
    "print (couples[:10], labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couples, labels\n",
      "[235, 2347],\t0\n",
      "[400, 972],\t0\n",
      "[871, 2987],\t0\n",
      "[3100, 1085],\t1\n",
      "[1491, 5],\t1\n",
      "[1763, 3995],\t0\n",
      "[3083, 21],\t1\n",
      "[4382, 3546],\t1\n",
      "[1850, 130],\t1\n",
      "[1013, 2837],\t0\n"
     ]
    }
   ],
   "source": [
    "print ('couples, labels')\n",
    "for i in range(10):\n",
    "    print ('{},\\t{}'.format(couples[i], labels[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Keras model using functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_target = keras.layers.Input((1,))\n",
    "input_context = keras.layers.Input((1,))\n",
    "\n",
    "embedding = keras.layers.Embedding(\n",
    "    vocab_size,\n",
    "    vector_dim,\n",
    "    input_length=1,\n",
    "    name='embedding'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = embedding(input_target)\n",
    "target = keras.layers.Reshape((vector_dim, 1))(target)\n",
    "\n",
    "context = embedding(input_context)\n",
    "context = keras.layers.Reshape((vector_dim, 1))(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"reshape/Reshape:0\", shape=(?, 300, 1), dtype=float32)\n",
      "Tensor(\"reshape_1/Reshape:0\", shape=(?, 300, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (target)\n",
    "print (context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity = keras.layers.merge(\n",
    "    [target, context],\n",
    "    mode = 'cos',\n",
    "    dot_axes = 0\n",
    ")\n",
    "\n",
    "K = keras.backend\n",
    "\n",
    "def l2_norm(x, axis=None):\n",
    "    \"\"\"\n",
    "    takes an input tensor and returns the l2 norm along specified axis\n",
    "    \"\"\"\n",
    "\n",
    "    square_sum = K.sum(K.square(x), axis=axis, keepdims=True)\n",
    "    norm = K.sqrt(K.maximum(square_sum, K.epsilon()))\n",
    "\n",
    "    return norm\n",
    "\n",
    "def pairwise_cosine_sim(A_B):\n",
    "    \"\"\"\n",
    "    A [batch x n x d] tensor of n rows with d dimensions\n",
    "    B [batch x m x d] tensor of n rows with d dimensions\n",
    "\n",
    "    returns:\n",
    "    D [batch x n x m] tensor of cosine similarity scores between each point i<n, j<m\n",
    "    \"\"\"\n",
    "\n",
    "    A_tensor, B_tensor = A_B\n",
    "    A_mag = l2_norm(A, axis=2)\n",
    "    B_mag = l2_norm(B, axis=2)\n",
    "    num = K.batch_dot(A_tensor, K.permute_dimensions(B_tensor, (0,2,1)))\n",
    "    den = (A_mag * K.permute_dimensions(B_mag, (0,2,1)))\n",
    "    dist_mat =  num / den\n",
    "\n",
    "    return dist_mat\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = keras.layers.dot(\n",
    "    inputs=[target, context],\n",
    "    axes=0,\n",
    "    normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product = keras.layers.dot(\n",
    "    [target, context],\n",
    "    axes=1,\n",
    "    normalize=False\n",
    ")\n",
    "\n",
    "dot_product = keras.layers.Reshape((1,))(dot_product)\n",
    "output = keras.layers.Dense(1, activation=tf.nn.sigmoid)(dot_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(\n",
    "    inputs = [input_target, input_context],\n",
    "    outputs = output\n",
    ")\n",
    "model.compile(\n",
    "    loss=keras.losses.binary_crossentropy,\n",
    "    optimizer=keras.optimizers.RMSprop()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 300)       1500000     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 300, 1)       0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 300, 1)       0           embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 1)         0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1)            0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2           reshape_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,500,002\n",
      "Trainable params: 1,500,002\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_model = keras.Model(\n",
    "    inputs = [input_target, input_context],\n",
    "    outputs = similarity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityCallback:\n",
    "    def run_sim(self):\n",
    "        for i in range(valid_size):\n",
    "            valid_word = reverse_dictionray[valid_examples[i]]\n",
    "            top_k = 6   # Number nearest neighbors\n",
    "            sim = self._get_sim(valid_examples[i])\n",
    "            nearest = (-sim).argsort()[1:top_k + 1]\n",
    "            log_str = 'Nearest to %s:' % valid_word\n",
    "            for k in range(top_k):\n",
    "                close_word = reverse_dictionray[nearest[k]]\n",
    "                log_str = '%s %s, ' % (log_str, close_word)\n",
    "            print (log_str)\n",
    "            \n",
    "    @staticmethod\n",
    "    def _get_sim(valid_word_index):\n",
    "        sim = np.zeros((vocab_size,))\n",
    "        in_arr1 = np.zeros((1,))\n",
    "        in_arr2 = np.zeros((1,))\n",
    "        in_arr1[0,] = valid_word_index\n",
    "        for i in range(vocab_size):\n",
    "            in_arr2[0,] = i\n",
    "            out = validation_model.predict_on_batch([in_arr1, in_arr2])\n",
    "            sim[i] = out\n",
    "        return sim\n",
    "    \n",
    "sim_cb = SimilarityCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\john.conway\\AppData\\Local\\Continuum\\anaconda3\\envs\\Sandbox\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss=1.0000001537946446e-07\n",
      "Nearest to called: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to their: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to on: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to it: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to while: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to from: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to all: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to when: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to a: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to known: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to has: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to of: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to or: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to would: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to over: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to he: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Iteration 250, loss=16.11809539794922\n",
      "Iteration 500, loss=16.11809539794922\n",
      "Iteration 750, loss=16.11809539794922\n",
      "Iteration 1000, loss=1.0000001537946446e-07\n",
      "Iteration 1250, loss=1.0000001537946446e-07\n",
      "Iteration 1500, loss=1.0000001537946446e-07\n",
      "Iteration 1750, loss=16.11809539794922\n",
      "Iteration 2000, loss=1.0000001537946446e-07\n",
      "Iteration 2250, loss=1.0000001537946446e-07\n",
      "Iteration 2500, loss=16.11809539794922\n",
      "Iteration 2750, loss=1.0000001537946446e-07\n",
      "Iteration 3000, loss=1.0000001537946446e-07\n",
      "Iteration 3250, loss=16.11809539794922\n",
      "Iteration 3500, loss=1.0000001537946446e-07\n",
      "Iteration 3750, loss=16.11809539794922\n",
      "Iteration 4000, loss=16.11809539794922\n",
      "Iteration 4250, loss=16.11809539794922\n",
      "Iteration 4500, loss=1.0000001537946446e-07\n",
      "Iteration 4750, loss=16.11809539794922\n",
      "Iteration 5000, loss=16.11809539794922\n",
      "Iteration 5250, loss=1.0000001537946446e-07\n",
      "Iteration 5500, loss=16.11809539794922\n",
      "Iteration 5750, loss=1.0000001537946446e-07\n",
      "Iteration 6000, loss=16.11809539794922\n",
      "Iteration 6250, loss=16.11809539794922\n",
      "Iteration 6500, loss=16.11809539794922\n",
      "Iteration 6750, loss=1.0000001537946446e-07\n",
      "Iteration 7000, loss=16.11809539794922\n",
      "Iteration 7250, loss=16.11809539794922\n",
      "Iteration 7500, loss=16.11809539794922\n",
      "Iteration 7750, loss=16.11809539794922\n",
      "Iteration 8000, loss=1.0000001537946446e-07\n",
      "Iteration 8250, loss=16.11809539794922\n",
      "Iteration 8500, loss=1.0000001537946446e-07\n",
      "Iteration 8750, loss=16.11809539794922\n",
      "Iteration 9000, loss=1.0000001537946446e-07\n",
      "Iteration 9250, loss=16.11809539794922\n",
      "Iteration 9500, loss=1.0000001537946446e-07\n",
      "Iteration 9750, loss=16.11809539794922\n",
      "Iteration 10000, loss=1.0000001537946446e-07\n",
      "Nearest to called: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to their: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to on: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to it: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to while: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to from: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to all: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to when: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to a: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to known: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to has: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to of: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to or: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to would: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to over: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to he: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Iteration 10250, loss=1.0000001537946446e-07\n",
      "Iteration 10500, loss=1.0000001537946446e-07\n",
      "Iteration 10750, loss=1.0000001537946446e-07\n",
      "Iteration 11000, loss=1.0000001537946446e-07\n",
      "Iteration 11250, loss=1.0000001537946446e-07\n",
      "Iteration 11500, loss=16.11809539794922\n",
      "Iteration 11750, loss=16.11809539794922\n",
      "Iteration 12000, loss=1.0000001537946446e-07\n",
      "Iteration 12250, loss=1.0000001537946446e-07\n",
      "Iteration 12500, loss=1.0000001537946446e-07\n",
      "Iteration 12750, loss=1.0000001537946446e-07\n",
      "Iteration 13000, loss=16.11809539794922\n",
      "Iteration 13250, loss=16.11809539794922\n",
      "Iteration 13500, loss=1.0000001537946446e-07\n",
      "Iteration 13750, loss=1.0000001537946446e-07\n",
      "Iteration 14000, loss=16.11809539794922\n",
      "Iteration 14250, loss=1.0000001537946446e-07\n",
      "Iteration 14500, loss=16.11809539794922\n",
      "Iteration 14750, loss=16.11809539794922\n",
      "Iteration 15000, loss=16.11809539794922\n",
      "Iteration 15250, loss=16.11809539794922\n",
      "Iteration 15500, loss=16.11809539794922\n",
      "Iteration 15750, loss=1.0000001537946446e-07\n",
      "Iteration 16000, loss=16.11809539794922\n",
      "Iteration 16250, loss=16.11809539794922\n",
      "Iteration 16500, loss=1.0000001537946446e-07\n",
      "Iteration 16750, loss=16.11809539794922\n",
      "Iteration 17000, loss=16.11809539794922\n",
      "Iteration 17250, loss=1.0000001537946446e-07\n",
      "Iteration 17500, loss=16.11809539794922\n",
      "Iteration 17750, loss=1.0000001537946446e-07\n",
      "Iteration 18000, loss=16.11809539794922\n",
      "Iteration 18250, loss=1.0000001537946446e-07\n",
      "Iteration 18500, loss=1.0000001537946446e-07\n",
      "Iteration 18750, loss=1.0000001537946446e-07\n",
      "Iteration 19000, loss=16.11809539794922\n",
      "Iteration 19250, loss=16.11809539794922\n",
      "Iteration 19500, loss=1.0000001537946446e-07\n",
      "Iteration 19750, loss=16.11809539794922\n",
      "Iteration 20000, loss=1.0000001537946446e-07\n",
      "Nearest to called: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to their: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to on: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to it: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to while: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to from: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to all: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to when: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to a: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to known: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to has: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to of: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to or: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to would: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to over: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to he: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Iteration 20250, loss=16.11809539794922\n",
      "Iteration 20500, loss=1.0000001537946446e-07\n",
      "Iteration 20750, loss=16.11809539794922\n",
      "Iteration 21000, loss=1.0000001537946446e-07\n",
      "Iteration 21250, loss=1.0000001537946446e-07\n",
      "Iteration 21500, loss=16.11809539794922\n",
      "Iteration 21750, loss=1.0000001537946446e-07\n",
      "Iteration 22000, loss=1.0000001537946446e-07\n",
      "Iteration 22250, loss=1.0000001537946446e-07\n",
      "Iteration 22500, loss=1.0000001537946446e-07\n",
      "Iteration 22750, loss=16.11809539794922\n",
      "Iteration 23000, loss=16.11809539794922\n",
      "Iteration 23250, loss=1.0000001537946446e-07\n",
      "Iteration 23500, loss=16.11809539794922\n",
      "Iteration 23750, loss=16.11809539794922\n",
      "Iteration 24000, loss=16.11809539794922\n",
      "Iteration 24250, loss=1.0000001537946446e-07\n",
      "Iteration 24500, loss=16.11809539794922\n",
      "Iteration 24750, loss=1.0000001537946446e-07\n",
      "Iteration 25000, loss=16.11809539794922\n",
      "Iteration 25250, loss=1.0000001537946446e-07\n",
      "Iteration 25500, loss=1.0000001537946446e-07\n",
      "Iteration 25750, loss=1.0000001537946446e-07\n",
      "Iteration 26000, loss=1.0000001537946446e-07\n",
      "Iteration 26250, loss=1.0000001537946446e-07\n",
      "Iteration 26500, loss=16.11809539794922\n",
      "Iteration 26750, loss=16.11809539794922\n",
      "Iteration 27000, loss=16.11809539794922\n",
      "Iteration 27250, loss=16.11809539794922\n",
      "Iteration 27500, loss=16.11809539794922\n",
      "Iteration 27750, loss=16.11809539794922\n",
      "Iteration 28000, loss=1.0000001537946446e-07\n",
      "Iteration 28250, loss=16.11809539794922\n",
      "Iteration 28500, loss=1.0000001537946446e-07\n",
      "Iteration 28750, loss=16.11809539794922\n",
      "Iteration 29000, loss=16.11809539794922\n",
      "Iteration 29250, loss=1.0000001537946446e-07\n",
      "Iteration 29500, loss=1.0000001537946446e-07\n",
      "Iteration 29750, loss=16.11809539794922\n",
      "Iteration 30000, loss=1.0000001537946446e-07\n",
      "Nearest to called: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to their: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to on: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to it: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to while: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to from: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to all: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to when: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to a: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to known: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to has: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to of: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to or: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to would: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to over: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to he: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Iteration 30250, loss=1.0000001537946446e-07\n",
      "Iteration 30500, loss=1.0000001537946446e-07\n",
      "Iteration 30750, loss=16.11809539794922\n",
      "Iteration 31000, loss=16.11809539794922\n",
      "Iteration 31250, loss=16.11809539794922\n",
      "Iteration 31500, loss=16.11809539794922\n",
      "Iteration 31750, loss=1.0000001537946446e-07\n",
      "Iteration 32000, loss=1.0000001537946446e-07\n",
      "Iteration 32250, loss=16.11809539794922\n",
      "Iteration 32500, loss=16.11809539794922\n",
      "Iteration 32750, loss=16.11809539794922\n",
      "Iteration 33000, loss=16.11809539794922\n",
      "Iteration 33250, loss=1.0000001537946446e-07\n",
      "Iteration 33500, loss=16.11809539794922\n",
      "Iteration 33750, loss=16.11809539794922\n",
      "Iteration 34000, loss=16.11809539794922\n",
      "Iteration 34250, loss=1.0000001537946446e-07\n",
      "Iteration 34500, loss=1.0000001537946446e-07\n",
      "Iteration 34750, loss=16.11809539794922\n",
      "Iteration 35000, loss=16.11809539794922\n",
      "Iteration 35250, loss=1.0000001537946446e-07\n",
      "Iteration 35500, loss=1.0000001537946446e-07\n",
      "Iteration 35750, loss=1.0000001537946446e-07\n",
      "Iteration 36000, loss=1.0000001537946446e-07\n",
      "Iteration 36250, loss=1.0000001537946446e-07\n",
      "Iteration 36500, loss=16.11809539794922\n",
      "Iteration 36750, loss=16.11809539794922\n",
      "Iteration 37000, loss=1.0000001537946446e-07\n",
      "Iteration 37250, loss=1.0000001537946446e-07\n",
      "Iteration 37500, loss=16.11809539794922\n",
      "Iteration 37750, loss=16.11809539794922\n",
      "Iteration 38000, loss=16.11809539794922\n",
      "Iteration 38250, loss=16.11809539794922\n",
      "Iteration 38500, loss=16.11809539794922\n",
      "Iteration 38750, loss=16.11809539794922\n",
      "Iteration 39000, loss=16.11809539794922\n",
      "Iteration 39250, loss=1.0000001537946446e-07\n",
      "Iteration 39500, loss=16.11809539794922\n",
      "Iteration 39750, loss=1.0000001537946446e-07\n",
      "Iteration 40000, loss=16.11809539794922\n",
      "Nearest to called: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to their: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to on: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to it: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to while: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to from: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to all: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to when: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to a: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to known: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to has: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to of: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to or: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to would: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to over: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to he: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Iteration 40250, loss=1.0000001537946446e-07\n",
      "Iteration 40500, loss=16.11809539794922\n",
      "Iteration 40750, loss=16.11809539794922\n",
      "Iteration 41000, loss=16.11809539794922\n",
      "Iteration 41250, loss=16.11809539794922\n",
      "Iteration 41500, loss=1.0000001537946446e-07\n",
      "Iteration 41750, loss=16.11809539794922\n",
      "Iteration 42000, loss=16.11809539794922\n",
      "Iteration 42250, loss=1.0000001537946446e-07\n",
      "Iteration 42500, loss=1.0000001537946446e-07\n",
      "Iteration 42750, loss=16.11809539794922\n",
      "Iteration 43000, loss=1.0000001537946446e-07\n",
      "Iteration 43250, loss=1.0000001537946446e-07\n",
      "Iteration 43500, loss=16.11809539794922\n",
      "Iteration 43750, loss=1.0000001537946446e-07\n",
      "Iteration 44000, loss=16.11809539794922\n",
      "Iteration 44250, loss=1.0000001537946446e-07\n",
      "Iteration 44500, loss=16.11809539794922\n",
      "Iteration 44750, loss=1.0000001537946446e-07\n",
      "Iteration 45000, loss=1.0000001537946446e-07\n",
      "Iteration 45250, loss=1.0000001537946446e-07\n",
      "Iteration 45500, loss=16.11809539794922\n",
      "Iteration 45750, loss=16.11809539794922\n",
      "Iteration 46000, loss=1.0000001537946446e-07\n",
      "Iteration 46250, loss=1.0000001537946446e-07\n",
      "Iteration 46500, loss=1.0000001537946446e-07\n",
      "Iteration 46750, loss=16.11809539794922\n",
      "Iteration 47000, loss=1.0000001537946446e-07\n",
      "Iteration 47250, loss=1.0000001537946446e-07\n",
      "Iteration 47500, loss=1.0000001537946446e-07\n",
      "Iteration 47750, loss=16.11809539794922\n",
      "Iteration 48000, loss=16.11809539794922\n",
      "Iteration 48250, loss=1.0000001537946446e-07\n",
      "Iteration 48500, loss=1.0000001537946446e-07\n",
      "Iteration 48750, loss=16.11809539794922\n",
      "Iteration 49000, loss=1.0000001537946446e-07\n",
      "Iteration 49250, loss=16.11809539794922\n",
      "Iteration 49500, loss=16.11809539794922\n",
      "Iteration 49750, loss=16.11809539794922\n",
      "Iteration 50000, loss=1.0000001537946446e-07\n",
      "Nearest to called: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to their: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to on: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to it: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to while: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to from: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to all: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to when: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to a: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to known: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to has: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to of: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to or: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to would: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to over: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to he: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Iteration 50250, loss=16.11809539794922\n",
      "Iteration 50500, loss=1.0000001537946446e-07\n",
      "Iteration 50750, loss=1.0000001537946446e-07\n",
      "Iteration 51000, loss=16.11809539794922\n",
      "Iteration 51250, loss=16.11809539794922\n",
      "Iteration 51500, loss=1.0000001537946446e-07\n",
      "Iteration 51750, loss=16.11809539794922\n",
      "Iteration 52000, loss=1.0000001537946446e-07\n",
      "Iteration 52250, loss=1.0000001537946446e-07\n",
      "Iteration 52500, loss=16.11809539794922\n",
      "Iteration 52750, loss=1.0000001537946446e-07\n",
      "Iteration 53000, loss=1.0000001537946446e-07\n",
      "Iteration 53250, loss=16.11809539794922\n",
      "Iteration 53500, loss=16.11809539794922\n",
      "Iteration 53750, loss=1.0000001537946446e-07\n",
      "Iteration 54000, loss=1.0000001537946446e-07\n",
      "Iteration 54250, loss=1.0000001537946446e-07\n",
      "Iteration 54500, loss=16.11809539794922\n",
      "Iteration 54750, loss=16.11809539794922\n",
      "Iteration 55000, loss=16.11809539794922\n",
      "Iteration 55250, loss=16.11809539794922\n",
      "Iteration 55500, loss=1.0000001537946446e-07\n",
      "Iteration 55750, loss=1.0000001537946446e-07\n",
      "Iteration 56000, loss=1.0000001537946446e-07\n",
      "Iteration 56250, loss=1.0000001537946446e-07\n",
      "Iteration 56500, loss=16.11809539794922\n",
      "Iteration 56750, loss=1.0000001537946446e-07\n",
      "Iteration 57000, loss=1.0000001537946446e-07\n",
      "Iteration 57250, loss=16.11809539794922\n",
      "Iteration 57500, loss=16.11809539794922\n",
      "Iteration 57750, loss=16.11809539794922\n",
      "Iteration 58000, loss=1.0000001537946446e-07\n",
      "Iteration 58250, loss=1.0000001537946446e-07\n",
      "Iteration 58500, loss=16.11809539794922\n",
      "Iteration 58750, loss=1.0000001537946446e-07\n",
      "Iteration 59000, loss=16.11809539794922\n",
      "Iteration 59250, loss=16.11809539794922\n",
      "Iteration 59500, loss=16.11809539794922\n",
      "Iteration 59750, loss=16.11809539794922\n",
      "Iteration 60000, loss=1.0000001537946446e-07\n",
      "Nearest to called: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to their: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to on: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to it: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to while: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to from: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to all: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to when: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to a: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to known: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to has: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to of: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to or: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to would: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to over: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to he: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Iteration 60250, loss=1.0000001537946446e-07\n",
      "Iteration 60500, loss=16.11809539794922\n",
      "Iteration 60750, loss=1.0000001537946446e-07\n",
      "Iteration 61000, loss=1.0000001537946446e-07\n",
      "Iteration 61250, loss=1.0000001537946446e-07\n",
      "Iteration 61500, loss=16.11809539794922\n",
      "Iteration 61750, loss=16.11809539794922\n",
      "Iteration 62000, loss=16.11809539794922\n",
      "Iteration 62250, loss=1.0000001537946446e-07\n",
      "Iteration 62500, loss=16.11809539794922\n",
      "Iteration 62750, loss=1.0000001537946446e-07\n",
      "Iteration 63000, loss=1.0000001537946446e-07\n",
      "Iteration 63250, loss=1.0000001537946446e-07\n",
      "Iteration 63500, loss=16.11809539794922\n",
      "Iteration 63750, loss=1.0000001537946446e-07\n",
      "Iteration 64000, loss=1.0000001537946446e-07\n",
      "Iteration 64250, loss=1.0000001537946446e-07\n",
      "Iteration 64500, loss=1.0000001537946446e-07\n",
      "Iteration 64750, loss=16.11809539794922\n",
      "Iteration 65000, loss=1.0000001537946446e-07\n",
      "Iteration 65250, loss=16.11809539794922\n",
      "Iteration 65500, loss=1.0000001537946446e-07\n",
      "Iteration 65750, loss=1.0000001537946446e-07\n",
      "Iteration 66000, loss=16.11809539794922\n",
      "Iteration 66250, loss=16.11809539794922\n",
      "Iteration 66500, loss=16.11809539794922\n",
      "Iteration 66750, loss=1.0000001537946446e-07\n",
      "Iteration 67000, loss=16.11809539794922\n",
      "Iteration 67250, loss=1.0000001537946446e-07\n",
      "Iteration 67500, loss=16.11809539794922\n",
      "Iteration 67750, loss=1.0000001537946446e-07\n",
      "Iteration 68000, loss=16.11809539794922\n",
      "Iteration 68250, loss=1.0000001537946446e-07\n",
      "Iteration 68500, loss=16.11809539794922\n",
      "Iteration 68750, loss=1.0000001537946446e-07\n",
      "Iteration 69000, loss=16.11809539794922\n",
      "Iteration 69250, loss=16.11809539794922\n",
      "Iteration 69500, loss=16.11809539794922\n",
      "Iteration 69750, loss=16.11809539794922\n",
      "Iteration 70000, loss=1.0000001537946446e-07\n",
      "Nearest to called: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to their: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to on: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n",
      "Nearest to it: describing,  libraries,  specialized,  virus,  cleveland,  firm, \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-a708ee8a9b71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Iteration {}, loss={}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcnt\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0msim_cb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_sim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-6170fd828913>\u001b[0m in \u001b[0;36mrun_sim\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mvalid_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreverse_dictionray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_examples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mtop_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m6\u001b[0m   \u001b[1;31m# Number nearest neighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0msim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_sim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_examples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[0mnearest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtop_k\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mlog_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Nearest to %s:'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalid_word\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-6170fd828913>\u001b[0m in \u001b[0;36m_get_sim\u001b[1;34m(valid_word_index)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0min_arr2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0min_arr1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_arr2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0msim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\Sandbox\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1632\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1634\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\Sandbox\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2895\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m     \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\Sandbox\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "arr_1 = np.zeros((1,))\n",
    "arr_2 = np.zeros((1,))\n",
    "arr_3 = np.zeros((1,))\n",
    "for cnt in range(epochs):\n",
    "    idx = np.random.randint(0, len(labels)-1)\n",
    "    arr_1[0,] = word_target[idx]\n",
    "    arr_2[0,] = word_context[idx]\n",
    "    arr_3[0,] = labels[idx]\n",
    "    loss = model.train_on_batch([arr_1, arr_2], arr_3)\n",
    "    if cnt % 250 == 0:\n",
    "        print(\"Iteration {}, loss={}\".format(cnt, loss))\n",
    "    if cnt % 10000 == 0:\n",
    "        sim_cb.run_sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
